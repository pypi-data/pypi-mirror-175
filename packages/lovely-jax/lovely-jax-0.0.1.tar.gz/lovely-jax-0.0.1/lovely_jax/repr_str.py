# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/00_repr_str.ipynb.

# %% auto 0
__all__ = ['PRINT_OPTS', 'pretty_str', 'lovely']

# %% ../nbs/00_repr_str.ipynb 3
from typing import Optional, Union
import jax.numpy as jnp
from jax import random

# %% ../nbs/00_repr_str.ipynb 4
class __PrinterOptions(object):
    precision: int = 3
    threshold_max: int = 3 # .abs() larger than 1e3 -> Sci mode
    threshold_min: int = -4 # .abs() smaller that 1e-4 -> Sci mode
    sci_mode: Optional[bool] = None # None = auto. Otherwise, force sci mode.
    indent: int = 2 # Indent for .deeper()
    color: bool = True

PRINT_OPTS = __PrinterOptions()

# %% ../nbs/00_repr_str.ipynb 5
# Do we want this float in decimal or scientific mode?
def sci_mode(f: float):
    return (abs(f) < 10**(PRINT_OPTS.threshold_min) or
            abs(f) > 10**PRINT_OPTS.threshold_max)

# %% ../nbs/00_repr_str.ipynb 8
# Convert a tensor or scalar into a string.
# This only looks good for small tensors, which is how it's intended to be used.
def pretty_str(x: Union[jnp.DeviceArray, float, int]):
    """A slightly better way to print `float`-y values"""

    if isinstance(x, int):
        return '{}'.format(x)
    elif isinstance(x, float):
        if x == 0.:
            return "0."

        sci = (PRINT_OPTS.sci_mode or
                (PRINT_OPTS.sci_mode is None and sci_mode(x)))
        # The f-string will generate something like "{.4f}", which is used
        # to format the value.
        return f"{{:.{PRINT_OPTS.precision}{'e' if sci else 'f'}}}".format(x)
    elif x.ndim == 0:
            return pretty_str(x.item())
    else:
        slices = [pretty_str(x[i]) for i in range(0, x.shape[0])]
        return '[' + ", ".join(slices) + ']'

# %% ../nbs/00_repr_str.ipynb 13
def space_join(lst: list):
    "Join non-empty list elements into a space-sepaeated string"
    return " ".join( [ l for l in lst if l] )

# %% ../nbs/00_repr_str.ipynb 15
dtnames = { jnp.dtype(k): v for k,v in {"float32": "",
                                        "float16": "f16",
                                        "float64": "f64",
                                        "uint8": "u8",
                                        "uint16": "u16",
                                        "uint32": "u32",
                                        "int8": "i8",
                                        "int16": "i16",
                                        "int32": "i32", }.items()
}
def short_dtype(x): return dtnames.get(x.dtype, str(x.dtype))

# %% ../nbs/00_repr_str.ipynb 16
def plain_repr(x):
    "Pick either x.__repr__ or x._plain_repr if __repr__ has been monkey-patched"
    return x._plain_repr() if hasattr(x.__class__, "_plain_repr") else x.__repr__()

# %% ../nbs/00_repr_str.ipynb 17
class StrProxy():
    def __init__(self, x: jnp.DeviceArray, plain=False, verbose=False, depth=0, lvl=0, color=None):
        self.x = x
        self.plain = plain
        self.verbose = verbose
        self.depth=depth
        self.lvl=lvl
        self.color=color

    # @torch.no_grad()
    def to_str(self):
        x : jnp.DeviceArray = self.x

        if self.plain or jnp.iscomplex(x).any():
            return plain_repr(x)

        color = PRINT_OPTS.color if self.color is None else self.color
        
        grey_style = "\x1b[38;2;127;127;127m" if color else ""
        red_style = "\x1b[31m" if color else ""
        end_style = "\x1b[0m" if color else ""

        tname = "DeviceArray" if type(x) is jnp.DeviceArray else type(x).__name__
        dev = None # XXX str(x.device) if x.device.type != "cpu" else None
        dtype = short_dtype(x)


        grad_fn = None# x.grad_fn.name() if x.grad_fn else None
        # All tensors along the compute path actually have required_grad=True.
        # Torch __repr__ just dones not show it.
        grad = None #"grad" if x.requires_grad else None

        shape = str(list(x.shape))

        # Later, we might be indexing 't' with a bool tensor derived from it. 
        # THis takes 4x memory and will result in a CUDA OOM if 't' is very large.
        # Move it to the cpu now - it won't matter for small tensors, and for
        # very large ones we trade a CUDA OOM for a few seconds delay.
        # x = x.detach().cpu()

        zeros = grey_style+"all_zeros"+end_style if not x.any() and x.size > 1 else None
        pinf = red_style+"+inf!"+end_style if jnp.isposinf(x).any() else None
        ninf = red_style+"-inf!"+end_style if jnp.isneginf(x).any() else None
        nan = red_style+"nan!"+end_style if jnp.isnan(x).any() else None

        attention = space_join([zeros,pinf,ninf,nan])

        vals = ""
        numel = f"n={x.size}" if x.size > 5 and max(x.shape) != x.size else None
        summary = None
        if not zeros:
            if x.size <= 10: vals = pretty_str(x)
            
        #     # Make sure it's float32. Also, we calculate stats on good values only.

            ft = jnp.extract(jnp.isfinite(x), x).astype(jnp.float32)

            minmax = f"x∈[{pretty_str(ft.min())}, {pretty_str(ft.max())}]" if ft.size > 2 else None
            meanstd = f"μ={pretty_str(ft.mean())} σ={pretty_str(ft.std())}" if ft.size >= 2 else None

            summary = space_join([minmax, meanstd])




        res = tname + space_join([  shape,
                                    numel,
                                    summary,
                                    dtype,
                                    grad,
                                    grad_fn,
                                    dev,
                                    attention,
                                    vals if not self.verbose else None])

        if self.verbose:
            res += "\n" + plain_repr(x)

        if self.depth and x.ndim > 1:
            res += "\n" + "\n".join([
                " "*PRINT_OPTS.indent*(self.lvl+1) +
                str(StrProxy(x[i,:], depth=self.depth-1, lvl=self.lvl+1))
                for i in range(x.shape[0])])

        return res
    
    def __repr__(self):
        return self.to_str()

    def __call__(self, depth=0):
        return StrProxy(self.x, depth=depth)

# %% ../nbs/00_repr_str.ipynb 19
def lovely(x: jnp.DeviceArray, # Tensor of interest
            verbose=False,  # Whether to show the full tensor
            plain=False,    # Just print if exactly as before
            depth=0,        # Show stats in depth
            color=None):    # Force color (True/False) or auto.
    return StrProxy(x, verbose=verbose, plain=plain, depth=depth, color=color)
