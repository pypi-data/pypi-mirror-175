{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# View as a summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp repr_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |hide\n",
    "from nbdev.showdoc import *\n",
    "from fastcore.test import test_eq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#| export\n",
    "from typing import Optional, Union\n",
    "import jax.numpy as jnp\n",
    "from jax import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |exports\n",
    "class __PrinterOptions(object):\n",
    "    precision: int = 3\n",
    "    threshold_max: int = 3 # .abs() larger than 1e3 -> Sci mode\n",
    "    threshold_min: int = -4 # .abs() smaller that 1e-4 -> Sci mode\n",
    "    sci_mode: Optional[bool] = None # None = auto. Otherwise, force sci mode.\n",
    "    indent: int = 2 # Indent for .deeper()\n",
    "    color: bool = True\n",
    "\n",
    "PRINT_OPTS = __PrinterOptions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |hide\n",
    "# |exporti\n",
    "\n",
    "# Do we want this float in decimal or scientific mode?\n",
    "def sci_mode(f: float):\n",
    "    return (abs(f) < 10**(PRINT_OPTS.threshold_min) or\n",
    "            abs(f) > 10**PRINT_OPTS.threshold_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |hide\n",
    "test_eq(sci_mode(1.), False)\n",
    "test_eq(sci_mode(0.00001), True)\n",
    "test_eq(sci_mode(10000000), True)\n",
    "\n",
    "# It would be fine either way, both `e` and `f` formats handle those.\n",
    "test_eq(sci_mode(float('nan')), False)\n",
    "test_eq(sci_mode(float('inf')), True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('{:.4e}', '1.2300e+00')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# |hide\n",
    "\n",
    "# What's happening in the cell below\n",
    "fmt = f\"{{:.{4}{'e'}}}\"\n",
    "fmt, fmt.format(1.23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |export\n",
    "\n",
    "# Convert a tensor or scalar into a string.\n",
    "# This only looks good for small tensors, which is how it's intended to be used.\n",
    "def pretty_str(x: Union[jnp.DeviceArray, float, int]):\n",
    "    \"\"\"A slightly better way to print `float`-y values\"\"\"\n",
    "\n",
    "    if isinstance(x, int):\n",
    "        return '{}'.format(x)\n",
    "    elif isinstance(x, float):\n",
    "        if x == 0.:\n",
    "            return \"0.\"\n",
    "\n",
    "        sci = (PRINT_OPTS.sci_mode or\n",
    "                (PRINT_OPTS.sci_mode is None and sci_mode(x)))\n",
    "        # The f-string will generate something like \"{.4f}\", which is used\n",
    "        # to format the value.\n",
    "        return f\"{{:.{PRINT_OPTS.precision}{'e' if sci else 'f'}}}\".format(x)\n",
    "    elif x.ndim == 0:\n",
    "            return pretty_str(x.item())\n",
    "    else:\n",
    "        slices = [pretty_str(x[i]) for i in range(0, x.shape[0])]\n",
    "        return '[' + \", \".join(slices) + ']'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = random.PRNGKey(0)\n",
    "randoms: jnp.DeviceArray = random.normal(key, (100,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spicy = (randoms[:12].at[0].mul(10000)\n",
    "                    .at[1].divide(10000)\n",
    "                    .at[3].set(float('inf'))\n",
    "                    .at[4].set(float('-inf'))\n",
    "                    .at[5].set(float('nan'))\n",
    "                    .reshape((2,6)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[[-1.981e+04, 0.000, 0.890, inf, -inf, nan], [0.031, -0.390, 0.013, -0.421, -1.234, -1.252]]'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretty_str(spicy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |hide\n",
    "test_eq(pretty_str(spicy), '[[-1.981e+04, 0.000, 0.890, inf, -inf, nan], [0.031, -0.390, 0.013, -0.421, -1.234, -1.252]]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |exporti\n",
    "# |hide\n",
    "def space_join(lst: list):\n",
    "    \"Join non-empty list elements into a space-sepaeated string\"\n",
    "    return \" \".join( [ l for l in lst if l] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |hide\n",
    "test_eq(space_join([\"Hello\", None, \"World\"]), 'Hello World')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |exporti\n",
    "\n",
    "dtnames = { jnp.dtype(k): v for k,v in {\"float32\": \"\",\n",
    "                                        \"float16\": \"f16\",\n",
    "                                        \"float64\": \"f64\",\n",
    "                                        \"uint8\": \"u8\",\n",
    "                                        \"uint16\": \"u16\",\n",
    "                                        \"uint32\": \"u32\",\n",
    "                                        \"int8\": \"i8\",\n",
    "                                        \"int16\": \"i16\",\n",
    "                                        \"int32\": \"i32\", }.items()\n",
    "}\n",
    "def short_dtype(x): return dtnames.get(x.dtype, str(x.dtype))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |exporti\n",
    "\n",
    "def plain_repr(x):\n",
    "    \"Pick either x.__repr__ or x._plain_repr if __repr__ has been monkey-patched\"\n",
    "    return x._plain_repr() if hasattr(x.__class__, \"_plain_repr\") else x.__repr__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "\n",
    "class StrProxy():\n",
    "    def __init__(self, x: jnp.DeviceArray, plain=False, verbose=False, depth=0, lvl=0, color=None):\n",
    "        self.x = x\n",
    "        self.plain = plain\n",
    "        self.verbose = verbose\n",
    "        self.depth=depth\n",
    "        self.lvl=lvl\n",
    "        self.color=color\n",
    "\n",
    "    # @torch.no_grad()\n",
    "    def to_str(self):\n",
    "        x : jnp.DeviceArray = self.x\n",
    "\n",
    "        if self.plain or jnp.iscomplex(x).any():\n",
    "            return plain_repr(x)\n",
    "\n",
    "        color = PRINT_OPTS.color if self.color is None else self.color\n",
    "        \n",
    "        grey_style = \"\\x1b[38;2;127;127;127m\" if color else \"\"\n",
    "        red_style = \"\\x1b[31m\" if color else \"\"\n",
    "        end_style = \"\\x1b[0m\" if color else \"\"\n",
    "\n",
    "        tname = \"DeviceArray\" if type(x) is jnp.DeviceArray else type(x).__name__\n",
    "        dev = None # XXX str(x.device) if x.device.type != \"cpu\" else None\n",
    "        dtype = short_dtype(x)\n",
    "\n",
    "\n",
    "        grad_fn = None# x.grad_fn.name() if x.grad_fn else None\n",
    "        # All tensors along the compute path actually have required_grad=True.\n",
    "        # Torch __repr__ just dones not show it.\n",
    "        grad = None #\"grad\" if x.requires_grad else None\n",
    "\n",
    "        shape = str(list(x.shape))\n",
    "\n",
    "        # Later, we might be indexing 't' with a bool tensor derived from it. \n",
    "        # THis takes 4x memory and will result in a CUDA OOM if 't' is very large.\n",
    "        # Move it to the cpu now - it won't matter for small tensors, and for\n",
    "        # very large ones we trade a CUDA OOM for a few seconds delay.\n",
    "        # x = x.detach().cpu()\n",
    "\n",
    "        zeros = grey_style+\"all_zeros\"+end_style if not x.any() and x.size > 1 else None\n",
    "        pinf = red_style+\"+inf!\"+end_style if jnp.isposinf(x).any() else None\n",
    "        ninf = red_style+\"-inf!\"+end_style if jnp.isneginf(x).any() else None\n",
    "        nan = red_style+\"nan!\"+end_style if jnp.isnan(x).any() else None\n",
    "\n",
    "        attention = space_join([zeros,pinf,ninf,nan])\n",
    "\n",
    "        vals = \"\"\n",
    "        numel = f\"n={x.size}\" if x.size > 5 and max(x.shape) != x.size else None\n",
    "        summary = None\n",
    "        if not zeros:\n",
    "            if x.size <= 10: vals = pretty_str(x)\n",
    "            \n",
    "        #     # Make sure it's float32. Also, we calculate stats on good values only.\n",
    "\n",
    "            ft = jnp.extract(jnp.isfinite(x), x).astype(jnp.float32)\n",
    "\n",
    "            minmax = f\"x∈[{pretty_str(ft.min())}, {pretty_str(ft.max())}]\" if ft.size > 2 else None\n",
    "            meanstd = f\"μ={pretty_str(ft.mean())} σ={pretty_str(ft.std())}\" if ft.size >= 2 else None\n",
    "\n",
    "            summary = space_join([minmax, meanstd])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        res = tname + space_join([  shape,\n",
    "                                    numel,\n",
    "                                    summary,\n",
    "                                    dtype,\n",
    "                                    grad,\n",
    "                                    grad_fn,\n",
    "                                    dev,\n",
    "                                    attention,\n",
    "                                    vals if not self.verbose else None])\n",
    "\n",
    "        if self.verbose:\n",
    "            res += \"\\n\" + plain_repr(x)\n",
    "\n",
    "        if self.depth and x.ndim > 1:\n",
    "            res += \"\\n\" + \"\\n\".join([\n",
    "                \" \"*PRINT_OPTS.indent*(self.lvl+1) +\n",
    "                str(StrProxy(x[i,:], depth=self.depth-1, lvl=self.lvl+1))\n",
    "                for i in range(x.shape[0])])\n",
    "\n",
    "        return res\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return self.to_str()\n",
    "\n",
    "    def __call__(self, depth=0):\n",
    "        return StrProxy(self.x, depth=depth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Would be _lovely_ if you could see all the important stats too!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |export\n",
    "def lovely(x: jnp.DeviceArray, # Tensor of interest\n",
    "            verbose=False,  # Whether to show the full tensor\n",
    "            plain=False,    # Just print if exactly as before\n",
    "            depth=0,        # Show stats in depth\n",
    "            color=None):    # Force color (True/False) or auto.\n",
    "    return StrProxy(x, verbose=verbose, plain=plain, depth=depth, color=color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DeviceArray[] -1.981\n",
      "DeviceArray[2] μ=-0.466 σ=1.515 [-1.981, 1.048]\n",
      "DeviceArray[2, 3] n=6 x∈[-1.981, 1.048] μ=-0.017 σ=1.113 [[-1.981, 1.048, 0.890], [0.035, -0.947, 0.851]]\n",
      "DeviceArray[11] x∈[-1.981, 1.048] μ=-0.191 σ=0.899\n"
     ]
    }
   ],
   "source": [
    "print(lovely(randoms[0]))\n",
    "print(lovely(randoms[:2]))\n",
    "print(lovely(randoms[:6].reshape((2, 3)))) # More than 2 elements -> show statistics\n",
    "print(lovely(randoms[:11])) # More than 10 -> suppress data output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |hide\n",
    "test_eq(str(lovely(randoms[0])), \"DeviceArray[] -1.981\")\n",
    "test_eq(str(lovely(randoms[:2])), \"DeviceArray[2] μ=-0.466 σ=1.515 [-1.981, 1.048]\")\n",
    "test_eq(str(lovely(randoms[:6].reshape((2, 3)))), \"DeviceArray[2, 3] n=6 x∈[-1.981, 1.048] μ=-0.017 σ=1.113 [[-1.981, 1.048, 0.890], [0.035, -0.947, 0.851]]\")\n",
    "test_eq(str(lovely(randoms[:11])), \"DeviceArray[11] x∈[-1.981, 1.048] μ=-0.191 σ=0.899\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |hide\n",
    "# grad = torch.tensor(1., requires_grad=True)\n",
    "# print(lovely(grad)); print(lovely(grad+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |hide\n",
    "# test_eq(str(lovely(grad)), \"tensor[] grad 1.000\")\n",
    "# test_eq(str(lovely(grad+1)), \"tensor[] grad AddBackward0 2.000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |hide\n",
    "# if torch.cuda.is_available():\n",
    "#     print(lovely(torch.tensor(1., device=torch.device(\"cuda:0\"))))\n",
    "#     test_eq(str(lovely(torch.tensor(1., device=torch.device(\"cuda:0\")))), \"tensor[] cuda:0 1.000\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do we have __any__ floating point nasties? Is the tensor __all__ zeros?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray[2, 6] n=12 x∈[-1.981e+04, 0.890] μ=-2.201e+03 σ=6.226e+03 \u001b[31m+inf!\u001b[0m \u001b[31m-inf!\u001b[0m \u001b[31mnan!\u001b[0m"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Statistics and range are calculated on good values only, if there are at lest 3 of them.\n",
    "lovely(spicy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray[2, 6] n=12 x∈[-1.981e+04, 0.890] μ=-2.201e+03 σ=6.226e+03 +inf! -inf! nan!"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lovely(spicy, color=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray[11] \u001b[31mnan!\u001b[0m"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lovely(jnp.array([float(\"nan\")]*11))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray[12] \u001b[38;2;127;127;127mall_zeros\u001b[0m"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lovely(jnp.zeros(12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(str(lovely(spicy)),\n",
    "    'DeviceArray[2, 6] n=12 x∈[-1.981e+04, 0.890] μ=-2.201e+03 σ=6.226e+03 \\x1b[31m+inf!\\x1b[0m \\x1b[31m-inf!\\x1b[0m \\x1b[31mnan!\\x1b[0m')\n",
    "test_eq(str(lovely(jnp.array([float(\"nan\")]*11))), 'DeviceArray[11] \\x1b[31mnan!\\x1b[0m')\n",
    "test_eq(str(lovely(jnp.zeros(12))), 'DeviceArray[12] \\x1b[38;2;127;127;127mall_zeros\\x1b[0m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray[2, 6] n=12 x∈[-1.981e+04, 0.890] μ=-2.201e+03 σ=6.226e+03 \u001b[31m+inf!\u001b[0m \u001b[31m-inf!\u001b[0m \u001b[31mnan!\u001b[0m\n",
       "DeviceArray([[-1.9810703e+04,  1.0481724e-04,  8.8981909e-01,\n",
       "                         inf,           -inf,            nan],\n",
       "             [ 3.1245498e-02, -3.8968593e-01,  1.3208009e-02,\n",
       "              -4.2052191e-01, -1.2335656e+00, -1.2524313e+00]],            dtype=float32)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.set_printoptions(linewidth=120)\n",
    "lovely(spicy, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray([[-1.9810703e+04,  1.0481724e-04,  8.8981909e-01,\n",
       "                         inf,           -inf,            nan],\n",
       "             [ 3.1245498e-02, -3.8968593e-01,  1.3208009e-02,\n",
       "              -4.2052191e-01, -1.2335656e+00, -1.2524313e+00]],            dtype=float32)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lovely(spicy, plain=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray[3, 196, 196] n=115248 x∈[-2.118, 2.640] μ=-0.388 σ=1.073 \u001b[31mnan!\u001b[0m\n",
       "  DeviceArray[196, 196] n=38416 x∈[-2.118, 2.249] μ=-0.324 σ=1.036\n",
       "  DeviceArray[196, 196] n=38416 x∈[-1.966, 2.429] μ=-0.274 σ=0.973 \u001b[31mnan!\u001b[0m\n",
       "  DeviceArray[196, 196] n=38416 x∈[-1.804, 2.640] μ=-0.567 σ=1.178"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numbers = jnp.load(\"mysteryman.npy\")\n",
    "numbers=  numbers.at[1,100,100].set(float('nan'))\n",
    "\n",
    "lovely(numbers, depth=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray([-1.8459435 -0.27444658j,  0.02393756-0.03172904j,\n",
       "              0.7681536 -1.4444252j , -1.0467294 +0.0560899j ,\n",
       "              0.3457446 +0.23581952j,  0.75131226+0.5628553j ,\n",
       "              0.38307393-1.0190806j ,  0.01203694-1.1971303j ,\n",
       "              0.1925229 -0.26424018j,  0.21582629-1.089025j  ],            dtype=complex64)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We don't really supposed complex numbers yet\n",
    "c = random.normal(key, (10,), dtype=jnp.complex64)\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('torch')",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
